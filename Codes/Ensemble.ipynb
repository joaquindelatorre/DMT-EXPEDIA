{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script creates an ensemble containing three models, which are logistic regression, \n",
    "decision tree and gradient boosting. \n",
    "\n",
    "Author: Ximeng Wang\n",
    "Date: 16/05/2020\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_run(df_x, df_y, test_set):\n",
    "    # Logistic regression\n",
    "    logreg = LogisticRegression(max_iter= 10000)\n",
    "    logreg.fit(df_x, df_y)\n",
    "    pred_logreg = logreg.predict(test_set)\n",
    "\n",
    "    # Decision tree classifier\n",
    "    dtree = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=14,\n",
    "                                   max_features='sqrt', max_leaf_nodes=10,\n",
    "                                   min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                   min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                   random_state=1, splitter='best')\n",
    "    dtree.fit(df_x, df_y)\n",
    "    pred_dtree = dtree.predict(test_set)\n",
    "\n",
    "    # Gradient boosting classifier\n",
    "    gbc = GradientBoostingClassifier()\n",
    "    gbc.fit(df_x, df_y)\n",
    "    pred_gbc = gbc.predict(test_set)\n",
    "    \n",
    "    # K-nearest neighbour classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors= 5)\n",
    "    knn.fit(df_x, df_y)\n",
    "    pred_knn = knn.predict(test_set)\n",
    "    \n",
    "    # Assign weightings on predictions of different models\n",
    "    test_label = 0.25 * pred_logreg + 0.1 * pred_dtree + 0.4 * pred_gbc + 0.25 * pred_knn\n",
    "    test_set= test_set.assign(label=test_label)\n",
    "    \n",
    "#     # Create ensemble table and take the mode for every array as class\n",
    "#     ensemble_table = pd.DataFrame()\n",
    "#     ensemble_table = ensemble_table.append(pd.Series(pred_logreg, name=\"logreg\"))\n",
    "#     ensemble_table = ensemble_table.append(pd.Series(pred_dtree, name=\"dtree\"))\n",
    "#     ensemble_table = ensemble_table.append(pd.Series(pred_gbc, name=\"gbc\"))\n",
    "#     ensemble_table = ensemble_table.append(pd.Series(pred_knn, name=\"knn\"))\n",
    "    \n",
    "    \n",
    "#     final_pred = ensemble_table.mode(axis = 0, numeric_only= False).iloc[0]\n",
    "#     test_set = test_set.assign(label= pd.Series(final_pred))\n",
    "\n",
    "    # Sort samples with the same 'srch_id' in descending order of 'label' value\n",
    "    test_set = test_set.groupby(['srch_id']).apply(lambda x:\n",
    "            x.sort_values(['label'], ascending =False)).reset_index(drop=True)\n",
    "\n",
    "    submission = test_set[['srch_id','prop_id']]\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read two data sets\n",
    "train_set = pd.read_csv('train_processed.csv')\n",
    "test_set = pd.read_csv('test_processed.csv')\n",
    "\n",
    "# Get features and class from the training set\n",
    "df_x = train_set.drop(columns = 'label')\n",
    "df_y = train_set.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ximengwang/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run ensemble_run and get final submission\n",
    "submission = ensemble_run(df_x, df_y, test_set)\n",
    "submission.to_csv(\"submission_2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
